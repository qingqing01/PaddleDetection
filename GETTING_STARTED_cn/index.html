<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>开始 - PaddleDetection Docs</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u5f00\u59cb";
    var mkdocs_page_input_path = "GETTING_STARTED_cn.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> PaddleDetection Docs</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../index.md">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docs/INSTALL.md">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docs/QUICK_STARTED.md">Quick start</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docs/MODEL_ZOO.md">Modle Zoo</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Deployment</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../docs/EXPORT_MODEL.md">Export model</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">PaddleDetection Docs</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>开始</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="_1">开始</h1>
<p>关于配置运行环境，请参考<a href="../INSTALL_cn/">安装指南</a></p>
<h2 id="_2">训练/评估/推断</h2>
<p>PaddleDetection提供了训练/评估/推断三个功能的使用脚本，支持通过不同可选参数实现特定功能</p>
<pre><code class="bash"># 设置PYTHONPATH路径
export PYTHONPATH=$PYTHONPATH:.
# GPU训练 支持单卡，多卡训练，通过CUDA_VISIBLE_DEVICES指定卡号
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
python tools/train.py -c configs/faster_rcnn_r50_1x.yml
# GPU评估
export CUDA_VISIBLE_DEVICES=0
python tools/eval.py -c configs/faster_rcnn_r50_1x.yml
# 推断
python tools/infer.py -c configs/faster_rcnn_r50_1x.yml --infer_img=demo/000000570688.jpg
</code></pre>

<h3 id="_3">可选参数列表</h3>
<p>以下列表可以通过<code>--help</code>查看</p>
<table>
<thead>
<tr>
<th align="center">FLAG</th>
<th align="center">支持脚本</th>
<th align="center">用途</th>
<th align="center">默认值</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">-c</td>
<td align="center">ALL</td>
<td align="center">指定配置文件</td>
<td align="center">None</td>
<td align="center"><strong>完整配置说明请参考<a href="config_example">配置案例</a></strong></td>
</tr>
<tr>
<td align="center">-o</td>
<td align="center">ALL</td>
<td align="center">设置配置文件里的参数内容</td>
<td align="center">None</td>
<td align="center">使用-o配置相较于-c选择的配置文件具有更高的优先级。例如：<code>-o use_gpu=False max_iter=10000</code></td>
</tr>
<tr>
<td align="center">-r/--resume_checkpoint</td>
<td align="center">train</td>
<td align="center">从某一检查点恢复训练</td>
<td align="center">None</td>
<td align="center"><code>-r output/faster_rcnn_r50_1x/10000</code></td>
</tr>
<tr>
<td align="center">--eval</td>
<td align="center">train</td>
<td align="center">是否边训练边测试</td>
<td align="center">False</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">--output_eval</td>
<td align="center">train/eval</td>
<td align="center">编辑评测保存json路径</td>
<td align="center">当前路径</td>
<td align="center"><code>--output_eval ./json_result</code></td>
</tr>
<tr>
<td align="center">-d/--dataset_dir</td>
<td align="center">train/eval</td>
<td align="center">数据集路径, 同配置文件里的dataset_dir</td>
<td align="center">None</td>
<td align="center"><code>-d dataset/coco</code></td>
</tr>
<tr>
<td align="center">--fp16</td>
<td align="center">train</td>
<td align="center">是否使用混合精度训练模式</td>
<td align="center">False</td>
<td align="center">需使用GPU训练</td>
</tr>
<tr>
<td align="center">--loss_scale</td>
<td align="center">train</td>
<td align="center">设置混合精度训练模式中损失值的缩放比例</td>
<td align="center">8.0</td>
<td align="center">需先开启<code>--fp16</code>后使用</td>
</tr>
<tr>
<td align="center">--json_eval</td>
<td align="center">eval</td>
<td align="center">是否通过已存在的bbox.json或者mask.json进行评估</td>
<td align="center">False</td>
<td align="center">json文件路径在<code>--output_eval</code>中设置</td>
</tr>
<tr>
<td align="center">--output_dir</td>
<td align="center">infer</td>
<td align="center">输出推断后可视化文件</td>
<td align="center"><code>./output</code></td>
<td align="center"><code>--output_dir output</code></td>
</tr>
<tr>
<td align="center">--draw_threshold</td>
<td align="center">infer</td>
<td align="center">可视化时分数阈值</td>
<td align="center">0.5</td>
<td align="center"><code>--draw_threshold 0.7</code></td>
</tr>
<tr>
<td align="center">--infer_dir</td>
<td align="center">infer</td>
<td align="center">用于推断的图片文件夹路径</td>
<td align="center">None</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">--infer_img</td>
<td align="center">infer</td>
<td align="center">用于推断的图片路径</td>
<td align="center">None</td>
<td align="center">相较于<code>--infer_dir</code>具有更高优先级</td>
</tr>
<tr>
<td align="center">--use_tb</td>
<td align="center">train/infer</td>
<td align="center">是否使用<a href="https://github.com/linshuliang/tb-paddle">tb-paddle</a>记录数据，进而在TensorBoard中显示</td>
<td align="center">False</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">--tb_log_dir</td>
<td align="center">train/infer</td>
<td align="center">指定 tb-paddle 记录数据的存储路径</td>
<td align="center">train:<code>tb_log_dir/scalar</code> infer: <code>tb_log_dir/image</code></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<h2 id="_4">使用示例</h2>
<h3 id="_5">模型训练</h3>
<ul>
<li>边训练边测试</li>
</ul>
<p><code>bash
  export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
  python -u tools/train.py -c configs/faster_rcnn_r50_1x.yml --eval -d dataset/coco</code></p>
<p>在训练中交替执行评估, 评估在每个snapshot_iter时开始。每次评估后还会评出最佳mAP模型保存到<code>best_model</code>文件夹下。</p>
<p>如果验证集很大，测试将会比较耗时，建议减少评估次数，或训练完再进行评估。</p>
<ul>
<li>Fine-tune其他任务</li>
</ul>
<p>使用预训练模型fine-tune其他任务时，可采用如下两种方式：</p>
<ol>
<li>在YAML配置文件中设置<code>finetune_exclude_pretrained_params</code></li>
<li>在命令行中添加-o finetune_exclude_pretrained_params对预训练模型进行选择性加载。</li>
</ol>
<p><code>bash
  export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
  python -u tools/train.py -c configs/faster_rcnn_r50_1x.yml \
                         -o pretrain_weights=output/faster_rcnn_r50_1x/model_final/ \
                            finetune_exclude_pretrained_params=['cls_score','bbox_pred']</code></p>
<p>详细说明请参考<a href="../TRANSFER_LEARNING_cn/">Transfer Learning</a></p>
<h4 id="_6">提示</h4>
<ul>
<li><code>CUDA_VISIBLE_DEVICES</code> 参数可以指定不同的GPU。例如: <code>export CUDA_VISIBLE_DEVICES=0,1,2,3</code>. GPU计算规则可以参考 <a href="#faq">FAQ</a></li>
<li>若本地未找到数据集，将自动下载数据集并保存在<code>~/.cache/paddle/dataset</code>中。</li>
<li>预训练模型自动下载并保存在<code>〜/.cache/paddle/weights</code>中。</li>
<li>模型checkpoints默认保存在<code>output</code>中，可通过修改配置文件中save_dir进行配置。</li>
<li>RCNN系列模型CPU训练在PaddlePaddle 1.5.1及以下版本暂不支持。</li>
</ul>
<h3 id="_7">混合精度训练</h3>
<p>通过设置 <code>--fp16</code> 命令行选项可以启用混合精度训练。目前混合精度训练已经在Faster-FPN, Mask-FPN 及 Yolov3 上进行验证，几乎没有精度损失（小于0.2 mAP)。</p>
<p>建议使用多进程方式来进一步加速混合精度训练。示例如下。</p>
<pre><code class="bash">python -m paddle.distributed.launch --selected_gpus 0,1,2,3,4,5,6,7 tools/train.py --fp16 -c configs/faster_rcnn_r50_fpn_1x.yml
</code></pre>

<p>如果训练过程中loss出现<code>NaN</code>，请尝试调节<code>--loss_scale</code>选项数值，细节请参看混合精度训练相关的<a href="https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html#mptrain">Nvidia文档</a>。</p>
<p>另外，请注意将配置文件中的 <code>norm_type</code> 由 <code>affine_channel</code> 改为 <code>bn</code>。</p>
<h3 id="_8">模型评估</h3>
<ul>
<li>指定权重和数据集路径</li>
</ul>
<p><code>bash
  export CUDA_VISIBLE_DEVICES=0
  python -u tools/eval.py -c configs/faster_rcnn_r50_1x.yml \
                        -o weights=https://paddlemodels.bj.bcebos.com/object_detection/faster_rcnn_r50_1x.tar \
                        -d dataset/coco</code></p>
<p>评估模型可以为本地路径，例如<code>output/faster_rcnn_r50_1x/model_final/</code>, 也可以为<a href="../MODEL_ZOO_cn/">MODEL_ZOO</a>中给出的模型链接。</p>
<ul>
<li>通过json文件评估</li>
</ul>
<p><code>bash
  export CUDA_VISIBLE_DEVICES=0
  python -u tools/eval.py -c configs/faster_rcnn_r50_1x.yml \
             --json_eval \
             --output_eval evaluation/</code></p>
<p>json文件必须命名为bbox.json或者mask.json，放在<code>evaluation/</code>目录下。</p>
<h4 id="_9">提示</h4>
<ul>
<li>R-CNN和SSD模型目前暂不支持多GPU评估，将在后续版本支持</li>
</ul>
<h3 id="_10">模型推断</h3>
<ul>
<li>设置输出路径 &amp;&amp; 设置推断阈值</li>
</ul>
<p><code>bash
  export CUDA_VISIBLE_DEVICES=0
  python -u tools/infer.py -c configs/faster_rcnn_r50_1x.yml \
                      --infer_img=demo/000000570688.jpg \
                      --output_dir=infer_output/ \
                      --draw_threshold=0.5 \
                      -o weights=output/faster_rcnn_r50_1x/model_final \</code></p>
<p><code>--draw_threshold</code> 是个可选参数. 根据 <a href="https://ieeexplore.ieee.org/document/1699659">NMS</a> 的计算，
  不同阈值会产生不同的结果。如果用户需要对自定义路径的模型进行推断，可以设置<code>-o weights</code>指定模型路径。</p>
<h2 id="faq">FAQ</h2>
<p><strong>Q:</strong>  为什么我使用单GPU训练loss会出<code>NaN</code>? </br>
<strong>A:</strong>  默认学习率是适配多GPU训练(8x GPU)，若使用单GPU训练，须对应调整学习率（例如，除以8）。
计算规则表如下所示，它们是等价的，表中变化节点即为<code>piecewise decay</code>里的<code>boundaries</code>: </br></p>
<table>
<thead>
<tr>
<th align="center">GPU数</th>
<th align="center">学习率</th>
<th align="center">最大轮数</th>
<th align="center">变化节点</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">2</td>
<td align="center">0.0025</td>
<td align="center">720000</td>
<td align="center">[480000, 640000]</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">0.005</td>
<td align="center">360000</td>
<td align="center">[240000, 320000]</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">0.01</td>
<td align="center">180000</td>
<td align="center">[120000, 160000]</td>
</tr>
</tbody>
</table>
<p><strong>Q:</strong>  如何减少GPU显存使用率? </br>
<strong>A:</strong>  可通过设置环境变量<code>FLAGS_conv_workspace_size_limit</code>为较小的值来减少显存消耗，并且不
会影响训练速度。以Mask-RCNN（R50）为例，设置<code>export FLAGS_conv_workspace_size_limit = 512</code>，
batch size可以达到每GPU 4 (Tesla V100 16GB)。</p>
<p><strong>Q:</strong>  如何修改数据预处理? </br>
<strong>A:</strong>  可在配置文件中设置 <code>sample_transform</code>。注意需要在配置文件中加入<strong>完整预处理</strong>
例如RCNN模型中<code>DecodeImage</code>, <code>NormalizeImage</code> and <code>Permute</code>。更多详细描述请参考<a href="config_example">配置案例</a>。</p>
<p><strong>Q:</strong> affine_channel和batch norm是什么关系?
<strong>A:</strong> 在RCNN系列模型加载预训练模型初始化，有时候会固定住batch norm的参数, 使用预训练模型中的全局均值和方式，并且batch norm的scale和bias参数不更新，已发布的大多ResNet系列的RCNN模型采用这种方式。这种情况下可以在config中设置norm_type为bn或affine_channel, freeze_norm为true (默认为true)，两种方式等价。affne_channel的计算方式为<code>scale * x + bias</code>。只不过设置affine_channel时，内部对batch norm的参数自动做了融合。如果训练使用的affine_channel，用保存的模型做初始化，训练其他任务时，即可使用affine_channel, 也可使用batch norm, 参数均可正确加载。</p>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../mathjax-config.js" defer></script>
      <script src="../MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
