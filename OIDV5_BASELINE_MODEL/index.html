<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>CascadeCA RCNN - PaddleDetection Docs</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "CascadeCA RCNN";
    var mkdocs_page_input_path = "OIDV5_BASELINE_MODEL.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> PaddleDetection Docs</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../index.md">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docs/INSTALL.md">Installation</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docs/QUICK_STARTED.md">Quick start</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../docs/MODEL_ZOO.md">Modle Zoo</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Deployment</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../docs/EXPORT_MODEL.md">Export model</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">PaddleDetection Docs</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>CascadeCA RCNN</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="cascadeca-rcnn">CascadeCA RCNN</h1>
<h2 id="_1">简介</h2>
<p>CascadeCA RCNN是百度视觉技术部在Google AI Open Images 2019-Object Detction比赛中的最佳单模型，该单模型助力团队在500多参数队伍中取得第二名。Open Images Dataset V5(OIDV5)包含500个类别、173W训练图像和超过1400W个标注边框，是目前已知规模最大的目标检测公开数据集，数据集地址：<a href="https://storage.googleapis.com/openimages/web/index.html">https://storage.googleapis.com/openimages/web/index.html</a>。团队在比赛中的技术方案报告地址：<a href="https://arxiv.org/pdf/1911.07171.pdf">https://arxiv.org/pdf/1911.07171.pdf</a></p>
<div align="center">
  <img src="../demo/oidv5_gt.png"/>
</div>

<h2 id="_2">方法描述</h2>
<p>该模型结合了当前较优的检测方法。具体地，它将ResNet200-vd作为检测模型的骨干网络，其imagenet分类预训练模型可以在<a href="https://github.com/PaddlePaddle/models/blob/develop/PaddleCV/image_classification/README_en.md">这里</a>下载；结合了CascadeCA RCNN、Feature Pyramid Networks、Non-local、Deformable V2等方法。在这里需要注意的是，标准的CascadeRCNN是只预测2个框（前景和背景，使用得分信息去判断最终前景所属的类别），而该模型对每个类别都单独预测了一个框（Cascade Class Aware）。最终模型框图如下图所示。</p>
<div align="center">
  <img src="../demo/oidv5_model_framework.png"/>
</div>

<p>由于OIDV5的类别不均衡现象比较严重，在训练时采用了动态采样的策略去选择样本并进行训练；多尺度训练被用于解决边框面积范围太大的情况；此外，团队使用Libra loss替代Smooth L1 loss，来计算预测框的loss；在预测时，使用SoftNMS方法进行后处理，保证更多的框可以被召回。</p>
<p>Objects365 Dataset和OIDV5有大约189个类别是重复的，因此将两个数据集合并进行训练，用于扩充OIDV5的训练数据，最终该模型与其性能指标如下表所示。更具体的模型训练和融合策略可以见：<a href="https://arxiv.org/pdf/1911.07171.pdf">OIDV5技术报告</a>。</p>
<p>OIDV5模型训练结果如下。</p>
<table>
<thead>
<tr>
<th align="center">模型结构</th>
<th align="center">Public/Private Score</th>
<th align="center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">CascadeCARCNN-FPN-Dcnv2-Nonlocal ResNet200-vd</td>
<td align="center">0.62690/0.59459</td>
<td align="center"><a href="https://paddlemodels.bj.bcebos.com/object_detection/oidv5_cascade_rcnn_cls_aware_r200_vd_fpn_dcnv2_nonlocal_softnms.tar">模型</a></td>
</tr>
</tbody>
</table>
<p>此外，为验证模型的性能，团队基于该模型结构，也训练了针对COCO2017和Objects365 Dataset的模型，模型和验证集指标如下表。</p>
<table>
<thead>
<tr>
<th align="center">模型结构</th>
<th align="center">数据集</th>
<th align="center">验证集mAP</th>
<th align="center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">CascadeCARCNN-FPN-Dcnv2-Nonlocal ResNet200-vd</td>
<td align="center">COCO2017</td>
<td align="center">51.7%</td>
<td align="center"><a href="https://paddlemodels.bj.bcebos.com/object_detection/cascade_rcnn_cls_aware_r200_vd_fpn_dcnv2_nonlocal_softnms.tar">模型</a></td>
</tr>
<tr>
<td align="center">CascadeCARCNN-FPN-Dcnv2-Nonlocal ResNet200-vd</td>
<td align="center">Objects365</td>
<td align="center">34.5%</td>
<td align="center"><a href="https://paddlemodels.bj.bcebos.com/object_detection/obj365_cascade_rcnn_cls_aware_r200_vd_fpn_dcnv2_nonlocal_softnms.tar">模型</a></td>
</tr>
</tbody>
</table>
<p>COCO和Objects365 Dataset数据格式相同，目前只支持预测和评估。</p>
<h2 id="_3">使用方法</h2>
<p>OIDV5数据集格式与COCO不同，目前仅支持单张图片的预测。OIDV5的模型评估方法可以参考<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/challenge_evaluation.md">这里</a></p>
<ol>
<li>
<p>下载模型并解压。</p>
</li>
<li>
<p>运行预测程序。</p>
</li>
</ol>
<pre><code>python -u tools/infer.py -c configs/oidv5/cascade_rcnn_cls_aware_r200_vd_fpn_dcnv2_nonlocal_softnms.yml -o weights=./oidv5_cascade_rcnn_cls_aware_r200_vd_fpn_dcnv2_nonlocal_softnms/ --infer_img=demo/000000570688.jpg
</code></pre>

<p>其中模型所在文件夹需要根据自己放置的位置进行修改。</p>
<p>检测结果图像可以在<code>output</code>文件夹中查看。</p>
<h2 id="_4">模型检测效果</h2>
<div align="center">
  <img src="../demo/oidv5_pred.jpg"/>
</div>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../mathjax-config.js" defer></script>
      <script src="../MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
